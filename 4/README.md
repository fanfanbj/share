#“宠物”模式与“牛车”模式
家禽不是宠物，这已经不是一个新的话题，已经成为业界非常常见的管理服务的新的方式。第一次看到这样的说法，觉得比喻非常好。那是今年6月份，那时，我才开始接触容器与微服务这方面的知识，Microservices Day London最后一篇精选演讲：《微服务与容器》，文中提到“微伸缩”的概念，介绍了谷歌和Netflix如何使用容器做到数据中心的超高利用率和对业务的弹性伸缩，也改变了我对弹性伸缩的认识。第二次看到这个比喻是在Pivotal案例实践中《企业级Java应用探秘及其如何推动“平台转换”》，他将JEE服务器放入Docker镜像中，比同把“宠物”塞入“牛车”中。两篇文章都肯定了Docker容器是非常棒，非常优秀的解决方案。

## 微伸缩
提到Paas平台，就会提到弹性伸缩这一概念。很长一段时间，我的售前PPT都有一页关于自动弹性伸缩。我不知道这个图的来源。就是觉得"很牛"。但仔细读来，发现还有错误。囧。

![image](https://github.com/fanfanbj/share/blob/master/4/scale.png)
自动弹性扩展也就出现在售前PPT中，因为它只是人们对容器的benefit的美好蓝图，却不明落地。现实场景中，弹性伸缩需要增加额外的资源而这绝不可能是实时的。但你可能可以通过容器实时的重用已经存在的资源。“如果我们在发生峰值时把这些时间不敏感的任务所使用的资源分给时间敏感的服务使用，或许我们就不需要弹性伸缩，也不需要提前预测需求”。这其实差不多就是谷歌和Netflix如何利用容器使得他们的系统能实时和自管理。

假如你提供了两种服务，一种是非常重要和时间敏感的，另外一个是重要的，但是时间上不敏感。一种是对时间非常敏感的高优先级服务，另外一种是低优先级服务，可能是批处理任务，不太在意用多长时间运”。我们可以利用调度器与编排系统协同去尽量满足业务的要求，而同时使用所有的其它资源运行批处理业务。

微伸缩的前提是微服务，Google的Borg所有的服务都是微服务。王总说，我们要以Google的Borg为标杆，它的服务抢占就是微伸缩的概念。服务抢占或服务微伸缩应该是Paas应该有的特性。Pivotal Cloud Foundry的应用弹性，是以开箱即用的cf scale命令行方式提供。是一种讨巧的办法。Openshift也采用同样的方式oc scale。

## Docker中的JEE服务器
在实施过程中，我曾将WLS服务器做过容器化部署。JEE服务器放入容器提供一种不变的打包格式，既轻松封装应用程序又方便与他人共享。官网提供了相应的解决方案，但当时只提供了单机解决方案，就是将AdminServer和ManagerServer容器化部署在一台主机上，使用--Link方式互通。随后，官网补充了跨主机的WLS集群容器化部署解决方案，是基于docker overlay网络，服务发现使用的是consul。

我想在数人云上发布WLS集群容器化应用。数人云的服务发现是用haproxy实现。WLS AS和MS通讯是基于T3协议，是TCP协议上实现的通讯协议。我做了一些尝试，使用Haproxy提供的四层的TCP代理。实践证明，使用Haproxy代理，AS可以和MS跨主机通讯。

之后，我使用marathon发布了这个“大宠物”到数人云平台，自动弹性伸缩，之后，资源配额不足。发布一直在“Waiting”状态。详细见我的repo：https://github.com/fanfanbj/1221-appdeploy

在Pivotal文章中写得，把JEE服务器放入Docker容器，是将“宠物”放入“牛车”，增加了运维的复杂度，例如，您现在需要确保 Docker 网络连接已配置，WLS 群集成员可以相互通信。如果某个 WLS 实例崩溃了，您不能像对待牛一样置之不理，因为此 WLS 实例关联了一个状态（JTA 交易日志和 JMS 永久消息），需要及时修复。是的，理论上您可以将 JMS 和 JTA 服务迁移到其他 WLS 实例中。

文中列举了将JEE服务器放入容器里所需要的运维和部署任务，如下图所示：
![image](https://github.com/fanfanbj/share/blob/master/4/jeeindocker.jpg)

同时，我想你还要关注WLS应用是否使用了CMP，两阶段XA，或JMS服务，并要留意应用的状态管理，cache管理的实现。这些都会增加WLS应用放入Docker中出现问题。路漫漫其修远兮，吾将上下而求索。

对于上表，Cloud Foundry BOSH开箱即用的部署，和服务可靠性：使用自定义代码／工具处理配置和外部服务查找／错误／追踪，容器云都可以设计相应的实现，来丰富自己平台特性。


